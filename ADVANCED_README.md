# Zen CLI - Advanced Technical Documentation

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Storage Backend System](#storage-backend-system)
3. [Configuration Management](#configuration-management)
4. [Project Isolation](#project-isolation)
5. [Concurrency & Thread Safety](#concurrency--thread-safety)
6. [Performance Optimization](#performance-optimization)
7. [Security Considerations](#security-considerations)
8. [Development Guide](#development-guide)
9. [Testing Framework](#testing-framework)
10. [Troubleshooting](#troubleshooting)

## Architecture Overview

### High-Level System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               Zen CLI Architecture                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ CLI Entry   â”‚â”€â”€â”€â–¶â”‚ Tool Router  â”‚â”€â”€â”€â–¶â”‚ AI Provider â”‚                   â”‚
â”‚  â”‚ (main.py)   â”‚    â”‚ (registry)   â”‚    â”‚ (gemini/gpt)â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                    â”‚                   â”‚                         â”‚
â”‚         â–¼                    â–¼                   â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚Config Mgr   â”‚    â”‚Storage Layer â”‚    â”‚Conversation â”‚                   â”‚
â”‚  â”‚(Hierarchy)  â”‚    â”‚(Multi-backendâ”‚    â”‚Memory       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                    â”‚                   â”‚                         â”‚
â”‚         â–¼                    â–¼                   â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚Project      â”‚    â”‚File/Redis/   â”‚    â”‚Session      â”‚                   â”‚
â”‚  â”‚Context      â”‚    â”‚Memory Storageâ”‚    â”‚Management   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### 1. CLI Entry Point (`main.py`)
- **Click-based command interface** with global options
- **Dynamic command registration** from tool modules
- **Context propagation** through Click context
- **Error handling and user feedback** with Rich formatting

#### 2. Tool System (`tools/`)
- **Modular tool architecture** with base class inheritance
- **Async execution pipeline** with proper error handling
- **Two-stage token optimization** (select â†’ execute)
- **System prompt management** with tool-specific prompts

#### 3. Storage Layer (`utils/storage_backend.py`)
- **Multi-backend abstraction** with factory pattern
- **Graceful fallback chain**: Redis â†’ File â†’ Memory
- **TTL-based expiration** across all backends
- **Health monitoring** and automatic recovery

#### 4. Configuration System (`utils/config_manager.py`)
- **Hierarchical configuration** with proper precedence
- **Thread-safe singleton** with proper locking
- **Project isolation** with inheritance
- **Atomic file operations** to prevent corruption

## Storage Backend System

### Backend Comparison Matrix

| Feature | File Storage | Redis Storage | Memory Storage |
|---------|-------------|---------------|----------------|
| Persistence | âœ… Persistent | âœ… Persistent | âŒ Session only |
| Scalability | ðŸ“ˆ Medium | ðŸ“ˆ High | ðŸ“ˆ Low |
| Performance | ðŸš€ Fast | ðŸš€ Very Fast | ðŸš€ Fastest |
| Concurrency | âš ï¸ Requires locking | âœ… Atomic ops | âœ… Isolated |
| Setup | âœ… Zero config | ðŸ”§ Redis required | âœ… Zero config |
| Memory Usage | ðŸ’¾ Low | ðŸ’¾ Medium | ðŸ’¾ High |
| Network Dependency | âŒ None | âœ… Required | âŒ None |

### File Storage Implementation

```python
class FileBasedStorage(StorageBackend):
    """File-based storage with JSON serialization and TTL"""
    
    def __init__(self, storage_dir: str = None):
        self.storage_dir = Path(storage_dir or "~/.zen-cli/conversations").expanduser()
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        self._lock = threading.RLock()
    
    def set_with_ttl(self, key: str, ttl: int, value: Any) -> None:
        """Thread-safe file storage with TTL metadata"""
        with self._lock:
            file_path = self.storage_dir / f"{key}.json"
            data = {
                'value': value,
                'created_at': time.time(),
                'ttl': ttl,
                'expires_at': time.time() + ttl
            }
            
            # Atomic write operation
            temp_file = file_path.with_suffix('.tmp')
            with open(temp_file, 'w') as f:
                json.dump(data, f, indent=2, default=str)
            temp_file.replace(file_path)
```

### Redis Storage Implementation

```python
class RedisStorage(StorageBackend):
    """Redis storage with connection pooling and atomic operations"""
    
    def __init__(self, host: str = "localhost", port: int = 6379, ...):
        self.pool = ConnectionPool(
            host=host, port=port, db=db, password=password,
            max_connections=10, retry_on_timeout=True,
            socket_connect_timeout=5, socket_timeout=5
        )
        self.redis = redis.Redis(connection_pool=self.pool)
        self.key_prefix = key_prefix
    
    def set_with_ttl(self, key: str, ttl: int, value: Any) -> None:
        """Atomic Redis operation with automatic expiration"""
        full_key = f"{self.key_prefix}{key}"
        serialized = json.dumps(value, default=str)
        
        # Atomic operation using pipeline
        with self.redis.pipeline() as pipe:
            pipe.multi()
            pipe.set(full_key, serialized)
            pipe.expire(full_key, ttl)
            pipe.execute()
```

### Backend Selection Logic

```python
def get_storage_backend() -> StorageBackend:
    """Factory function with graceful fallback chain"""
    storage_type = os.getenv("ZEN_STORAGE_TYPE", "file").lower()
    
    # Try requested backend first
    if storage_type == "redis":
        try:
            from .redis_storage import RedisStorage
            backend = RedisStorage()
            if backend.health_check()['healthy']:
                return backend
        except Exception as e:
            logger.warning(f"Redis backend failed, falling back to file: {e}")
            storage_type = "file"
    
    # Fallback chain
    if storage_type == "file":
        return FileBasedStorage()
    else:
        return InMemoryStorage()
```

## Configuration Management

### Hierarchical Configuration System

```
Environment Variables (Highest Priority)
    â†“
Project-Specific Configuration
    â†“  
Global User Configuration
    â†“
Built-in Defaults (Lowest Priority)
```

### Configuration Schema

```python
@dataclass
class GlobalConfig:
    """Root configuration object"""
    current_project: Optional[str] = None
    projects: Dict[str, ProjectConfig] = field(default_factory=dict)
    storage: StorageConfig = field(default_factory=StorageConfig)
    models: ModelConfig = field(default_factory=ModelConfig)
    session: SessionConfig = field(default_factory=SessionConfig)
    api_keys: Dict[str, str] = field(default_factory=dict)
    version: str = "1.0"

@dataclass
class ProjectConfig:
    """Project-specific configuration with inheritance"""
    name: str
    description: str = ""
    storage: StorageConfig = field(default_factory=StorageConfig)
    api_keys: Dict[str, str] = field(default_factory=dict)
    models: ModelConfig = field(default_factory=ModelConfig)
    session: SessionConfig = field(default_factory=SessionConfig)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    last_used: str = ""

@dataclass
class StorageConfig:
    """Storage backend configuration"""
    type: str = "file"  # file, redis, memory
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    redis_password: Optional[str] = None
    redis_key_prefix: str = "zen:"
    file_directory: str = "~/.zen-cli/conversations"
    cleanup_interval_hours: int = 24
```

### Thread-Safe Configuration Access

```python
class ConfigManager:
    """Thread-safe configuration manager with atomic operations"""
    
    def __init__(self, config_dir: str = None):
        self.config_dir = Path(config_dir or "~/.zen-cli").expanduser()
        self._lock = threading.RLock()
        self._config: Optional[GlobalConfig] = None
    
    def get_config(self) -> GlobalConfig:
        """Thread-safe configuration access with lazy loading"""
        with self._lock:
            if self._config is None:
                self._config = self._load_config()
            return self._config
    
    def save_config(self):
        """Atomic configuration persistence"""
        with self._lock:
            if self._config is not None:
                # Use temporary file for atomic operation
                temp_file = self.config_file.with_suffix('.json.tmp')
                with open(temp_file, 'w') as f:
                    json.dump(asdict(self._config), f, indent=2, default=str)
                temp_file.replace(self.config_file)
```

## Project Isolation

### Multi-Project Architecture

Projects in Zen CLI provide complete isolation of:
- **Conversations**: Separate storage namespaces per project
- **Configuration**: Project-specific settings with global inheritance
- **API Keys**: Per-project API key overrides
- **Storage Backends**: Different Redis instances per project

### Project Switching

```bash
# Create isolated projects
zen project create client_work "Client development work"
zen project create research "Personal AI research"

# Switch project context
zen project switch client_work

# Use project-specific settings
zen chat "Analyze client requirements" --project client_work
zen debug "Research memory optimization" --project research
```

### Project Configuration Examples

#### Enterprise Redis Project
```json
{
  "name": "enterprise_project",
  "description": "Enterprise development with Redis clustering",
  "storage": {
    "type": "redis",
    "redis_host": "redis-cluster.company.com",
    "redis_port": 6380,
    "redis_password": "secure_password",
    "redis_key_prefix": "zen:enterprise:",
    "redis_db": 5
  },
  "api_keys": {
    "openai": "sk-enterprise-key-...",
    "gemini": "enterprise-gemini-key..."
  },
  "models": {
    "default_provider": "openai",
    "preferred_fast": "gpt-4-turbo",
    "temperature": 0.3
  }
}
```

#### Development File Storage Project
```json
{
  "name": "local_dev",
  "description": "Local development with file storage",
  "storage": {
    "type": "file",
    "file_directory": "~/dev/zen-conversations"
  },
  "api_keys": {
    "gemini": "dev-gemini-key..."
  },
  "models": {
    "default_provider": "gemini",
    "preferred_fast": "flash"
  }
}
```

## Concurrency & Thread Safety

### Race Condition Analysis

**Problem**: Multiple `zen` processes using the same session ID can cause:
- **File Storage**: JSON read-modify-write race conditions
- **Redis Storage**: Connection pool exhaustion and transaction conflicts
- **Memory Storage**: No issues (isolated per process)

### Current Risks

```bash
# DANGEROUS: Can cause conversation corruption
zen chat "Message 1" --session shared &
zen chat "Message 2" --session shared &
zen chat "Message 3" --session shared &
```

**Risk Assessment**:
- **File Storage**: HIGH - JSON corruption, message loss
- **Redis Storage**: MEDIUM - Connection conflicts, rare transaction failures  
- **Memory Storage**: NONE - Process isolation prevents conflicts

### Recommended Solutions

#### File Storage Locking
```python
import fcntl
import time
from contextlib import contextmanager

class FileBasedStorage(StorageBackend):
    
    @contextmanager
    def _session_lock(self, session_id: str, timeout: float = 5.0):
        """Advisory file locking with timeout"""
        lock_file = self.storage_dir / f"{session_id}.lock"
        lock_fd = None
        start_time = time.time()
        
        try:
            # Try to acquire lock with timeout
            while time.time() - start_time < timeout:
                try:
                    lock_fd = os.open(lock_file, os.O_CREAT | os.O_WRONLY | os.O_EXCL)
                    fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                    break
                except (OSError, IOError):
                    time.sleep(0.1)
            else:
                raise TimeoutError(f"Could not acquire lock for session {session_id}")
            
            yield lock_fd
            
        finally:
            if lock_fd:
                fcntl.flock(lock_fd, fcntl.LOCK_UN)
                os.close(lock_fd)
                try:
                    os.unlink(lock_file)
                except OSError:
                    pass
```

#### Redis Atomic Operations
```python
class RedisStorage(StorageBackend):
    
    def add_message_atomic(self, session_id: str, role: str, content: str):
        """Atomic message addition with conflict detection"""
        full_key = f"{self.key_prefix}session:{session_id}:messages"
        message_data = {
            'role': role,
            'content': content,
            'timestamp': time.time(),
            'message_id': str(uuid.uuid4())
        }
        
        # Use transaction for atomicity
        with self.redis.pipeline() as pipe:
            while True:
                try:
                    # Watch for concurrent modifications
                    pipe.watch(full_key)
                    
                    # Get current messages
                    current = pipe.lrange(full_key, 0, -1)
                    
                    # Start transaction
                    pipe.multi()
                    pipe.lpush(full_key, json.dumps(message_data, default=str))
                    pipe.expire(full_key, self.ttl)
                    pipe.execute()
                    
                    break  # Success
                    
                except redis.WatchError:
                    # Retry on concurrent modification
                    continue
```

### Thread Safety Guidelines

1. **Always use locks** when modifying shared state
2. **Implement timeouts** to prevent deadlocks
3. **Use atomic operations** where possible (Redis transactions)
4. **Validate state** before modifications
5. **Clean up resources** properly in finally blocks

## Performance Optimization

### Token Usage Optimization

The Zen CLI maintains 95% token reduction through:

#### Two-Stage Architecture
```python
# Stage 1: Mode Selection (200 tokens)
mode_result = await select_mode_tool.execute(task_description)

# Stage 2: Optimized Execution (600-800 tokens)  
execution_result = await execute_tool.execute(
    mode=mode_result['mode'],
    request=optimized_parameters
)
```

#### Conversation Memory Management
```python
class ConversationMemory:
    def _cleanup_expired_sessions(self):
        """Automatic cleanup of expired conversations"""
        cutoff_time = time.time() - (24 * 3600)  # 24 hours
        
        for session_id in self.list_active_sessions():
            session_data = self.storage.get(f"session:{session_id}")
            if session_data and session_data.get('last_activity', 0) < cutoff_time:
                self.delete_session(session_id)
```

#### Context Compression Strategies
```python
def compress_conversation_context(self, session_id: str, max_tokens: int = 2000):
    """Intelligent context compression using AI"""
    history = self.get_conversation_history(session_id)
    
    if estimate_tokens(history) > max_tokens:
        # Summarize older messages while preserving recent context
        recent_messages = history[-10:]  # Keep last 10 messages
        older_messages = history[:-10]
        
        summary = await self.ai_provider.summarize(older_messages)
        compressed_history = [{"role": "system", "content": f"Previous conversation summary: {summary}"}] + recent_messages
        
        return compressed_history
    
    return history
```

### Storage Performance

#### File Storage Optimization
- **JSON streaming** for large conversations
- **Lazy loading** of conversation metadata
- **Background cleanup** of expired sessions
- **Compression** for archived conversations

#### Redis Performance
- **Connection pooling** prevents connection overhead
- **Pipeline operations** reduce network round trips
- **Lua scripts** for complex atomic operations
- **Memory optimization** with proper key expiration

```python
# Redis Pipeline Example
def batch_operations(self, operations: List[Dict]):
    """Batch multiple operations into single pipeline"""
    with self.redis.pipeline() as pipe:
        for op in operations:
            if op['type'] == 'set':
                pipe.set(op['key'], op['value'])
                pipe.expire(op['key'], op['ttl'])
            elif op['type'] == 'get':
                pipe.get(op['key'])
        
        return pipe.execute()
```

### Monitoring and Profiling

```python
import functools
import time
import logging

def profile_execution(func):
    """Decorator for performance profiling"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time
            
            logging.info(f"{func.__name__} executed in {execution_time:.2f}s")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logging.error(f"{func.__name__} failed after {execution_time:.2f}s: {e}")
            raise
    
    return wrapper
```

## Security Considerations

### Current Security Posture

#### âœ… Implemented Security Features
- **Input validation** for all CLI parameters
- **Path traversal protection** for file operations
- **API key environment variable support**
- **JSON schema validation** for configuration
- **Error message sanitization** to prevent information leakage

#### âš ï¸ Security Concerns

1. **API Key Storage**
   ```python
   # CURRENT: Plaintext storage
   {
     "api_keys": {
       "openai": "sk-plaintext-key...",
       "gemini": "plaintext-gemini-key..."
     }
   }
   
   # RECOMMENDED: Encrypted storage
   {
     "api_keys": {
       "openai": "encrypted:gAAAAABh...",
       "gemini": "encrypted:gAAAAABh..."
     }
   }
   ```

2. **Conversation Data**
   - Currently stored in plaintext
   - No encryption at rest
   - Potential sensitive information exposure

3. **Network Security**
   - Redis connections without TLS by default
   - No certificate validation for HTTPS requests
   - API provider connections could be intercepted

#### ðŸ”’ Recommended Security Enhancements

##### API Key Encryption
```python
from cryptography.fernet import Fernet
import keyring

class SecureConfigManager:
    def __init__(self):
        self.encryption_key = self._get_or_create_encryption_key()
        self.cipher = Fernet(self.encryption_key)
    
    def _get_or_create_encryption_key(self) -> bytes:
        """Use system keyring for key management"""
        key = keyring.get_password("zen-cli", "encryption_key")
        if not key:
            key = Fernet.generate_key().decode()
            keyring.set_password("zen-cli", "encryption_key", key)
        return key.encode()
    
    def encrypt_api_key(self, api_key: str) -> str:
        """Encrypt API key for storage"""
        return self.cipher.encrypt(api_key.encode()).decode()
    
    def decrypt_api_key(self, encrypted_key: str) -> str:
        """Decrypt API key for use"""
        return self.cipher.decrypt(encrypted_key.encode()).decode()
```

##### TLS Configuration
```python
# Redis with TLS
redis_config = {
    'host': 'redis.example.com',
    'port': 6380,
    'ssl': True,
    'ssl_cert_reqs': 'required',
    'ssl_ca_certs': '/path/to/ca.crt',
    'ssl_certfile': '/path/to/client.crt',
    'ssl_keyfile': '/path/to/client.key'
}
```

##### Conversation Data Protection
```python
class EncryptedConversationMemory:
    def _encrypt_conversation_data(self, data: dict) -> dict:
        """Encrypt sensitive conversation content"""
        encrypted_data = data.copy()
        
        # Encrypt message content
        if 'messages' in encrypted_data:
            for message in encrypted_data['messages']:
                message['content'] = self.cipher.encrypt(
                    message['content'].encode()
                ).decode()
        
        return encrypted_data
```

## Development Guide

### Setting Up Development Environment

```bash
# 1. Clone repository
git clone <repository-url>
cd zen-cli

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# 3. Install in development mode
pip install -e .

# 4. Set up pre-commit hooks
pip install pre-commit
pre-commit install

# 5. Set environment variables
export GEMINI_API_KEY="your_gemini_key"
export OPENAI_API_KEY="your_openai_key"
export ZEN_STORAGE_TYPE="file"  # or "redis" or "memory"
```

### Adding New Tools

```python
# 1. Create tool in tools/ directory
from zen_cli.tools.shared.base_tool import BaseTool

class MyNewTool(BaseTool):
    """Custom tool implementation"""
    
    async def execute(self, **kwargs) -> dict:
        """Tool execution logic"""
        try:
            # Tool implementation here
            result = await self.perform_tool_operation(**kwargs)
            
            return {
                'status': 'success',
                'result': result,
                'metadata': {
                    'tool': 'mynew',
                    'model_used': kwargs.get('model'),
                    'execution_time': time.time()
                }
            }
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e),
                'error_type': type(e).__name__
            }

# 2. Add CLI command in main.py
@cli.command()
@click.option('--param', help='Tool parameter')
@common_options
def mynew(ctx, param, **kwargs):
    """My new tool description"""
    tool = MyNewTool()
    result = asyncio.run(tool.execute(param=param, **kwargs))
    format_output(result, ctx.obj.get('format', 'auto'), 'mynew')
```

### Adding New Storage Backends

```python
# 1. Implement StorageBackend interface
from zen_cli.utils.storage_backend import StorageBackend

class MyStorageBackend(StorageBackend):
    """Custom storage backend implementation"""
    
    def __init__(self, **config):
        self.config = config
        # Initialize your storage system
    
    def set_with_ttl(self, key: str, ttl: int, value: Any) -> None:
        """Implement storage with TTL"""
        pass
    
    def get(self, key: str) -> Optional[Any]:
        """Implement retrieval"""
        pass
    
    def exists(self, key: str) -> bool:
        """Check if key exists and is not expired"""
        pass
    
    def delete(self, key: str) -> None:
        """Delete key"""
        pass
    
    def list_keys(self, pattern: str = "*") -> List[str]:
        """List matching keys"""
        pass
    
    def health_check(self) -> dict:
        """Return health status"""
        return {
            'healthy': True,
            'storage_type': 'my_storage',
            'details': {}
        }

# 2. Register in storage_backend.py
def get_storage_backend() -> StorageBackend:
    storage_type = os.getenv("ZEN_STORAGE_TYPE", "file").lower()
    
    if storage_type == "my_storage":
        from .my_storage import MyStorageBackend
        return MyStorageBackend(**get_storage_config())
    # ... other backends
```

### Code Style Guidelines

```python
# Use type hints throughout
def process_conversation(session_id: str, messages: List[Dict[str, str]]) -> Dict[str, Any]:
    pass

# Proper error handling
try:
    result = await risky_operation()
except SpecificException as e:
    logger.error(f"Specific error occurred: {e}")
    return {'status': 'error', 'message': str(e)}
except Exception as e:
    logger.exception("Unexpected error")
    return {'status': 'error', 'message': 'Internal error occurred'}

# Use dataclasses for structured data
@dataclass
class ToolResult:
    status: str
    result: Any
    metadata: Dict[str, Any] = field(default_factory=dict)
    
# Async/await best practices
async def tool_execution_pipeline(tool: BaseTool, **kwargs) -> ToolResult:
    """Properly structured async function"""
    async with get_conversation_lock(kwargs.get('session_id')):
        result = await tool.execute(**kwargs)
        await update_conversation_memory(result)
        return result
```

## Testing Framework

### Test Structure

```
tests/
â”œâ”€â”€ test_config.py              # Configuration management tests
â”œâ”€â”€ test_storage_backends.py    # Storage backend tests
â”œâ”€â”€ test_cli_tools.py          # CLI tool integration tests
â”œâ”€â”€ test_conversation_memory.py # Conversation memory tests
â”œâ”€â”€ test_providers.py          # AI provider tests
â”œâ”€â”€ run_tests.py              # Test runner
â””â”€â”€ fixtures/                 # Test data fixtures
    â”œâ”€â”€ sample_conversations.json
    â”œâ”€â”€ test_configs/
    â””â”€â”€ mock_responses/
```

### Running Tests

```bash
# Run all tests
python tests/run_tests.py

# Run specific test category
python -m pytest tests/test_config.py -v

# Run with coverage
python -m pytest tests/ --cov=zen_cli --cov-report=html

# Run integration tests
python -m pytest tests/ -m integration

# Run performance benchmarks
python -m pytest tests/ -m benchmark --benchmark-only
```

### Test Categories

#### Unit Tests
```python
def test_storage_backend_basic_operations():
    """Test basic CRUD operations"""
    storage = FileBasedStorage()
    
    # Test set and get
    storage.set_with_ttl("test_key", 3600, "test_value")
    assert storage.get("test_key") == "test_value"
    assert storage.exists("test_key") == True
    
    # Test delete
    storage.delete("test_key")
    assert storage.get("test_key") is None
    assert storage.exists("test_key") == False
```

#### Integration Tests
```python
@pytest.mark.integration
async def test_end_to_end_conversation():
    """Test complete conversation flow"""
    # Setup
    config_manager = ConfigManager()
    storage = get_storage_backend()
    memory = ConversationMemory(storage)
    tool = ChatTool()
    
    # Execute
    session_id = "integration_test"
    result = await tool.execute(
        message="Hello, test conversation",
        model="test-model",
        session=session_id,
        conversation_memory=memory
    )
    
    # Verify
    assert result['status'] == 'success'
    history = memory.get_conversation_history(session_id)
    assert len(history) >= 1
```

#### Performance Tests
```python
@pytest.mark.benchmark
def test_storage_performance(benchmark):
    """Benchmark storage operations"""
    storage = FileBasedStorage()
    
    def storage_operations():
        for i in range(100):
            storage.set_with_ttl(f"key_{i}", 3600, f"value_{i}")
            storage.get(f"key_{i}")
    
    result = benchmark(storage_operations)
    assert result is not None
```

#### Load Tests
```python
@pytest.mark.load
def test_concurrent_session_access():
    """Test concurrent access to same session"""
    import threading
    import time
    
    storage = FileBasedStorage()
    memory = ConversationMemory(storage)
    session_id = "load_test_session"
    errors = []
    
    def add_message(message_id):
        try:
            memory.add_message(session_id, "user", f"Message {message_id}")
        except Exception as e:
            errors.append(e)
    
    # Create 10 concurrent threads
    threads = []
    for i in range(10):
        thread = threading.Thread(target=add_message, args=(i,))
        threads.append(thread)
        thread.start()
    
    # Wait for completion
    for thread in threads:
        thread.join()
    
    # Verify results
    assert len(errors) == 0  # No race conditions
    history = memory.get_conversation_history(session_id)
    assert len(history) == 10  # All messages saved
```

### Mock Testing

```python
from unittest.mock import patch, MagicMock

@patch('zen_cli.providers.openai_provider.OpenAIProvider.execute')
async def test_chat_tool_with_mock(mock_execute):
    """Test chat tool with mocked AI provider"""
    # Setup mock
    mock_execute.return_value = {
        'status': 'success',
        'result': 'Mocked AI response',
        'metadata': {'model_used': 'gpt-4', 'tokens_used': 150}
    }
    
    # Execute test
    tool = ChatTool()
    result = await tool.execute(
        message="Test message",
        model="gpt-4"
    )
    
    # Verify
    assert result['status'] == 'success'
    assert result['result'] == 'Mocked AI response'
    mock_execute.assert_called_once()
```

## Troubleshooting

### Common Issues

#### 1. API Key Problems
```bash
# Symptom: "No API key found for provider"
# Solution: Set environment variables
export GEMINI_API_KEY="your_key_here"
export OPENAI_API_KEY="your_key_here"

# Verify keys are set
zen listmodels
```

#### 2. Storage Backend Issues
```bash
# Symptom: Redis connection failures
# Check Redis connectivity
redis-cli ping

# Fallback to file storage
export ZEN_STORAGE_TYPE=file

# Check file permissions
ls -la ~/.zen-cli/
```

#### 3. Configuration Problems
```bash
# Check configuration health
zen config health

# Reset configuration
rm -rf ~/.zen-cli/config.json
zen config show  # Will recreate with defaults
```

#### 4. Import/Module Errors
```bash
# Check Python path
python -c "import zen_cli; print(zen_cli.__file__)"

# Reinstall in development mode
pip install -e .

# Check for conflicts
pip list | grep zen
```

### Debug Mode

```bash
# Enable verbose logging
export ZEN_DEBUG=1
zen chat "Debug test message" --verbose

# Check log files
tail -f ~/.zen-cli/logs/zen-cli.log
```

### Performance Debugging

```python
# Profile tool execution
import cProfile
import pstats

def profile_tool_execution():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Your tool execution here
    result = asyncio.run(tool.execute(**kwargs))
    
    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 functions
    
    return result
```

### Memory Usage Analysis

```bash
# Monitor memory usage
pip install memory-profiler
python -m memory_profiler zen-script.py

# Check conversation storage size
du -h ~/.zen-cli/conversations/

# Monitor Redis memory
redis-cli info memory
```

### Network Debugging

```bash
# Test Redis connectivity
telnet redis-host 6379

# Monitor network traffic
tcpdump -i any port 6379

# Check SSL/TLS issues
openssl s_client -connect redis-host:6380 -servername redis-host
```

---

## Conclusion

The Zen CLI represents a sophisticated, production-ready AI development platform with enterprise-grade features including multi-backend storage, comprehensive project management, and robust security considerations. The modular architecture enables easy extension and customization while maintaining high performance and reliability.

The comprehensive testing framework, detailed documentation, and thorough error handling make this tool suitable for both individual developers and enterprise teams requiring scalable AI-powered development assistance.

For additional support or contribution guidelines, please refer to the main README.md and project documentation.

---

*Advanced README - Last updated: 2025-01-09*  
*Version: 2.0 (Post-Autonomous Development Session)*